{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3D stack - Batch processing - Marker+ based on average intensity</h2>\n",
    "\n",
    "The following notebook is able to process a 3D stack (.czi or .nd2 files) and using the parameters tested in <code>000_SP_Avg_Intensity</code> allows you to:\n",
    "\n",
    "1. Read previously defined ROIs, if not present, full image is analyzed.\n",
    "2. Read previously predicted nuclei labels, if not present, generates them.\n",
    "3. Extract numbers of cells positive for all marker based on signal average intensity within the nuclear or cytoplasmic compartments (using a user-defined min-max range).\n",
    "4. Extract and save per label per ROI per marker data in a .csv file (filename_per_label_avg_int_.csv).\n",
    "5. Extract and save number and % of positive cells in a .csv file (BP_marker_+_label_avg_int.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tifffile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops_table\n",
    "from utils_stardist import get_gpu_details, list_images, read_image, maximum_intensity_projection, extract_nuclei_stack, get_stardist_model, simulate_cytoplasm, simulate_cell, simulate_cytoplasm_chunked_3d, simulate_cell_chunked_3d, segment_nuclei, remove_labels_touching_roi_edge\n",
    "\n",
    "get_gpu_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the directory for your images (.nd2 or .czi files) and cell marker info</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "directory_path = Path(\"../raw_data/test_data\")\n",
    "\n",
    "# Define the channels you want to analyze using the following structure:\n",
    "# markers = [(channel_name, channel_nr, cellular_location),(..., ..., ...)]\n",
    "# cellular locations can be \"nucleus\", \"cytoplasm\" or \"cell\" (cell being the sum volume of nucleus and cytoplasm)\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# i.e. markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define you batch analysis parameters</h3>\n",
    "\n",
    "If you have generated nuclei predictions already, make sure to input the same <code>slicing factor</code> you used when generating nuclei predictions. \n",
    "\n",
    "If you have not generated nuclei predictions before, input <code>nuclei_channel</code>, <code>n_tiles</code>, <code>segmentation_type</code> and <code>model_name</code> values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "slicing_factor_xy = None # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 3\n",
    "\n",
    "# The n_tiles parameter defines the number of tiles the input volume/image will be divided into along each dimension (z, y, x) during prediction. \n",
    "# This is useful for processing large images that may not fit into memory at once.\n",
    "# While tiling can handle memory limitations, chopping the image into smaller chunks increases\n",
    "# the processing time for stitching the predictions back together. \n",
    "# Use n_tiles=(1, 1, 1) if the input volume fits in memory without tiling to minimize processing overhead.\n",
    "n_tiles=(1,4,4)\n",
    "\n",
    "# Segmentation type (\"2D\" or \"3D\"). \n",
    "# 2D takes a z-stack as input, performs MIP (Maximum Intensity Projection) and predicts nuclei from the resulting projection (faster, useful for single layers of cells)\n",
    "# 3D is more computationally expensive. Predicts 3D nuclear volumes, useful for multilayered structures\n",
    "segmentation_type = \"3D\"\n",
    "\n",
    "# Nuclear segmentation model type (\"Stardist\")\n",
    "# Choose your Stardist fine-tuned model (model_name) from stardist_models folder\n",
    "# If no custom model is present, type \"test\" and a standard pre-trained model will be loaded\n",
    "model_name = \"MEC0.1\" # Type \"test\" if you don't have a custom model trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define in <code>min_max_per_marker</code> the <code>marker</code> you want to use to define your cell populations of interest, the <code>min_max</code> range of avg_int and the <code>population</code> name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the min_max average intensity parameters to select your populations of interest\n",
    "# You have the possibility to define populations for the same marker (i.e. neun high and neun low)\n",
    "# max_values are set to 255 since the test input images are 8-bit, higher bit depths can result in higher max avg_int values\n",
    "\n",
    "min_max_per_marker = [{\"marker\": \"ki67\", \"min_max\": (110,255), \"population\":\"ki67\"},\n",
    "                      {\"marker\": \"neun\", \"min_max\": (20,80), \"population\":\"neun_low\"},\n",
    "                      {\"marker\": \"neun\", \"min_max\": (80,255), \"population\":\"neun_high\"},\n",
    "                      {\"marker\": \"calbindin\", \"min_max\": (25,255), \"population\":\"calbindin\"},]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Run Batch Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "nuclei_preds_path =  directory_path / \"nuclei_preds\" / segmentation_type / model_name\n",
    "\n",
    "# Extract the experiment name from the data directory path\n",
    "experiment_id = directory_path.name\n",
    "\n",
    "# List of subfolder names\n",
    "try:\n",
    "    roi_names = [folder.name for folder in roi_path.iterdir() if folder.is_dir()]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    roi_names = [\"full_image\"]\n",
    "        \n",
    "print(f\"The following regions of interest will be analyzed: {roi_names}\")\n",
    "\n",
    "model = None  # Initialize model variable\n",
    "\n",
    "for image in tqdm(images):\n",
    "\n",
    "    # Read image, apply slicing if needed and return filename and img as a np array\n",
    "    img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "\n",
    "    # Generate maximum intensity projection \n",
    "    img_mip = maximum_intensity_projection(img)\n",
    "\n",
    "    # Initialize an empty list to hold the extracted dataframes on a per ROI basis\n",
    "    per_roi_props = []\n",
    "\n",
    "    for roi_name in roi_names:\n",
    "\n",
    "        print(f\"\\nAnalyzing ROI: {roi_name}\")\n",
    "\n",
    "        # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "        props_list = []\n",
    "\n",
    "        # Read the user defined ROIs, in case of full image analysis generate a label covering the entire image\n",
    "        try:\n",
    "            # Read previously defined ROIs\n",
    "            user_roi = tifffile.imread(roi_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # Extract the xy dimensions of the input image \n",
    "            img_shape = img_mip.shape\n",
    "            img_xy_dims = img_shape[-2:]\n",
    "\n",
    "            # Create a label covering the entire image\n",
    "            user_roi = np.ones(img_xy_dims).astype(np.uint8)\n",
    "\n",
    "        # Read previously predicted nuclei labels, if not present generate nuclei predictions and save them\n",
    "        try:\n",
    "            # Read the nuclei predictions per ROI\n",
    "            nuclei_labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "            print(f\"Pre-computed nuclei labels found for {filename}\")\n",
    "            # Remove labels touching ROI edge (in place for nuclei predictions generated before \"remove_labels_touching_roi_edge\" was implemented)\n",
    "            print(\"Removing nuclei labels touching ROI edge\")\n",
    "            nuclei_labels = remove_labels_touching_roi_edge(nuclei_labels, user_roi)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "\n",
    "            print(f\"Generating nuclei labels for {filename}\")\n",
    "            \n",
    "            # If 3D-segmentation input nuclei_img is a 3D-stack\n",
    "            if segmentation_type == \"3D\":\n",
    "                # Slice the nuclei stack\n",
    "                nuclei_img = extract_nuclei_stack(img, nuclei_channel)\n",
    "\n",
    "            # If 2D-segmentation input nuclei_img is a max intensity projection of said 3D-stack\n",
    "            elif segmentation_type == \"2D\":\n",
    "                # Slice the nuclei stack\n",
    "                nuclei_img = extract_nuclei_stack(img, nuclei_channel)\n",
    "                nuclei_img = np.max(nuclei_img, axis=0)\n",
    "\n",
    "            # We will create a mask where roi is greater than or equal to 1\n",
    "            mask = (user_roi >= 1).astype(np.uint8)\n",
    "\n",
    "            # 3D segmentation logic, extend 2D mask across the entire stack volume\n",
    "            if segmentation_type == \"3D\":\n",
    "                # Extract the number of z-slices to extend the mask\n",
    "                slice_nr = img.shape[1]\n",
    "                # Extend the mask across the entire volume\n",
    "                mask = np.tile(mask, (slice_nr, 1, 1))\n",
    "                # Apply the mask to nuclei_img, setting all other pixels to 0\n",
    "                masked_nuclei_img = np.where(mask, nuclei_img, 0)\n",
    "            else:\n",
    "                # Apply the mask to nuclei_img, setting all other pixels to 0\n",
    "                masked_nuclei_img = np.where(mask, nuclei_img, 0)\n",
    "\n",
    "            if model is None: # Load the model only once\n",
    "                # Model loading (only if the files are missing) - saves VRAM\n",
    "                model = get_stardist_model(segmentation_type, name=model_name, basedir='stardist_models')\n",
    "\n",
    "            # Segment nuclei and return labels\n",
    "            nuclei_labels = segment_nuclei(masked_nuclei_img, segmentation_type, model, n_tiles)\n",
    "\n",
    "            # Remove labels touching ROI edge\n",
    "            print(\"Removing nuclei labels touching ROI edge\")\n",
    "            nuclei_labels = remove_labels_touching_roi_edge(nuclei_labels, user_roi)\n",
    "\n",
    "            # Save nuclei labels as .tiff files to reuse them later\n",
    "            try:\n",
    "                os.makedirs(nuclei_preds_path / roi_name, exist_ok=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating directory {nuclei_preds_path / roi_name}: {e}\")\n",
    "\n",
    "            # Construct path to store\n",
    "            path_to_store = nuclei_preds_path / roi_name / f\"{filename}.tiff\"\n",
    "            print(f\"Saving nuclei labels to {path_to_store}\")\n",
    "            try:\n",
    "                tifffile.imwrite(path_to_store, nuclei_labels)\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving file {path_to_store}: {e}\")\n",
    "\n",
    "        # Create a dictionary containing all image descriptors\n",
    "        descriptor_dict = {\n",
    "                    \"filename\": filename,\n",
    "                    \"ROI\": roi_name,\n",
    "                    }\n",
    "\n",
    "        # Loop through each channel and extract the average intensity within either nuclei or cytoplasmic regions\n",
    "        for tuple in markers:\n",
    "\n",
    "            channel_name = tuple[0]\n",
    "            ch_nr = tuple[1]\n",
    "            location = tuple[2]\n",
    "\n",
    "            print(f\"Analyzing channel: {channel_name}\")\n",
    "\n",
    "            if location == \"cytoplasm\":\n",
    "                if segmentation_type == \"3D\":\n",
    "                    print(f\"Generating {segmentation_type} cytoplasm labels for: {channel_name}\")\n",
    "                    # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "                    cytoplasm_labels = simulate_cytoplasm_chunked_3d(nuclei_labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "                    # Extract intensity information from each marker channel\n",
    "                    props = regionprops_table(label_image=cytoplasm_labels,\n",
    "                                            intensity_image=img[ch_nr],\n",
    "                                            properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "                elif segmentation_type == \"2D\":\n",
    "                    print(f\"Generating {segmentation_type} cytoplasm labels for: {channel_name}\")\n",
    "                    # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "                    cytoplasm_labels = simulate_cytoplasm(nuclei_labels, dilation_radius=2, erosion_radius=0)\n",
    "                    # Extract intensity information from each marker channel\n",
    "                    props = regionprops_table(label_image=cytoplasm_labels,\n",
    "                                            intensity_image=img_mip[ch_nr],\n",
    "                                            properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "            elif location == \"cell\":\n",
    "                if segmentation_type == \"3D\":\n",
    "                    print(f\"Generating {segmentation_type} cell labels for: {channel_name}\")\n",
    "                    # Simulate a cell volume by dilating the nuclei \n",
    "                    cell_labels = simulate_cell_chunked_3d(nuclei_labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "                    # Extract intensity information from each marker channel\n",
    "                    props = regionprops_table(label_image=cell_labels,\n",
    "                                            intensity_image=img[ch_nr],\n",
    "                                            properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "                elif segmentation_type == \"2D\":\n",
    "                    print(f\"Generating {segmentation_type} cell labels for: {channel_name}\")\n",
    "                    # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "                    cell_labels = simulate_cell(nuclei_labels, dilation_radius=2, erosion_radius=0)\n",
    "                    # Extract intensity information from each marker channel\n",
    "                    props = regionprops_table(label_image=cell_labels,\n",
    "                                            intensity_image=img_mip[ch_nr],\n",
    "                                            properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "            elif location == \"nucleus\":\n",
    "                if segmentation_type == \"3D\":\n",
    "                    # Extract intensity information from each marker channel\n",
    "                    props = regionprops_table(label_image=nuclei_labels,\n",
    "                                            intensity_image=img[ch_nr],\n",
    "                                            properties=[\"label\", \"intensity_mean\"])\n",
    "                elif segmentation_type == \"2D\":\n",
    "                    # Extract intensity information from each marker channel\n",
    "                    props = regionprops_table(label_image=nuclei_labels,\n",
    "                                            intensity_image=img_mip[ch_nr],\n",
    "                                            properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "            # Convert to dataframe\n",
    "            props_df = pd.DataFrame(props)\n",
    "\n",
    "            # Rename intensity_mean column to indicate the specific image\n",
    "            props_df.rename(columns={\"intensity_mean\": f\"{location}_{channel_name}_avg_int\"}, inplace=True)\n",
    "\n",
    "            # Append each props_df to props_list\n",
    "            props_list.append(props_df)\n",
    "\n",
    "            # Initialize the df with the first df in the list\n",
    "            props_df = props_list[0]\n",
    "            # Start looping from the second df in the list\n",
    "            for df in props_list[1:]:\n",
    "                props_df = props_df.merge(df, on=\"label\")\n",
    "\n",
    "        # Add each key-value pair from descriptor_dict to props_df at the specified position\n",
    "        insertion_position = 0    \n",
    "        for key, value in descriptor_dict.items():\n",
    "            props_df.insert(insertion_position, key, value)\n",
    "            insertion_position += 1  # Increment position to maintain the order of keys in descriptor_dict\n",
    "\n",
    "        # Append each props_df to props_list\n",
    "        per_roi_props.append(props_df)\n",
    "\n",
    "    final_df = pd.concat(per_roi_props, ignore_index=True)\n",
    "\n",
    "    # Create a 'results' folder in the root directory\n",
    "    results_folder = Path(\"results\") / experiment_id / segmentation_type / model_name\n",
    "\n",
    "    try:\n",
    "        os.makedirs(results_folder)\n",
    "        print(f\"'{results_folder}' folder created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"'{results_folder}' folder already exists.\")\n",
    "\n",
    "    # Save the df containing per_label results into a CSV file\n",
    "    final_df.to_csv(results_folder / f'{filename}_per_label_avg_int.csv')\n",
    "\n",
    "    # Select all column names in 'final_df' that contain the substring 'avg_int'\n",
    "    avg_int_columns = [col for col in final_df.columns if 'avg_int' in col]\n",
    "\n",
    "    # Create an empty list to store all stats extracted from each image\n",
    "    stats = []\n",
    "\n",
    "    for marker_analysis in min_max_per_marker:\n",
    "\n",
    "        marker = marker_analysis[\"marker\"]\n",
    "        min_max_avg_int = marker_analysis[\"min_max\"]\n",
    "        population = marker_analysis[\"population\"]\n",
    "\n",
    "        # Retrieve the column name from which the avg_int values should be read\n",
    "        for column in avg_int_columns:\n",
    "            if marker in column:\n",
    "                column_name = column\n",
    "\n",
    "        for roi_name in roi_names:\n",
    "\n",
    "            # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "            props_list = []\n",
    "\n",
    "            # Retrieve the first and second values (channel and location) of the corresponding tuple in markers\n",
    "            for item in markers:\n",
    "                if item[0] == marker:\n",
    "                    channel = item[1]\n",
    "                    location = item[2]\n",
    "                    break  # Stop searching once the marker is found\n",
    "\n",
    "            # Read the nuclei predictions per ROI\n",
    "            nuclei_labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "            # Filter rows in final_df where ROI matches roi_name and column_name is within min < avg_int <= max values.\n",
    "            filtered_df = final_df[(final_df[\"ROI\"] == roi_name) & (final_df[column_name] > min_max_avg_int[0]) & (final_df[column_name] <= min_max_avg_int[1])]\n",
    "\n",
    "            # Get the values of the 'label' column in filtered_df as a list\n",
    "            label_values = filtered_df[\"label\"].tolist()\n",
    "\n",
    "            # Create a boolean mask where each element is True if the corresponding value in 'nuclei_labels' \n",
    "            # is found in 'label_values', and False otherwise\n",
    "            mask = np.isin(nuclei_labels, label_values)\n",
    "\n",
    "            # Use the mask to set values in 'nuclei_labels' that are not in 'label_values' to 0,\n",
    "            # creating a new array 'filtered_labels' with only the specified values retained\n",
    "            filtered_labels = np.where(mask, nuclei_labels, 0)\n",
    "\n",
    "            # Extract your information of interest\n",
    "            total_nuclei = len(np.unique(nuclei_labels)) - 1\n",
    "            marker_pos_nuclei = len(np.unique(filtered_labels)) - 1\n",
    "\n",
    "            # Calculate \"%_marker+_cells\" and avoid division by zero errors\n",
    "            try:\n",
    "                perc_marker_pos_cells = (marker_pos_nuclei * 100) / total_nuclei\n",
    "            except ZeroDivisionError:\n",
    "                perc_marker_pos_cells = 0\n",
    "\n",
    "            # Create a dictionary containing all extracted info per masked image\n",
    "            stats_dict = {\n",
    "                        \"filename\": filename,\n",
    "                        \"ROI\": roi_name,\n",
    "                        \"based_on\": column_name,\n",
    "                        \"marker\": marker,\n",
    "                        \"population\":population,\n",
    "                        \"marker_ch\": channel,\n",
    "                        \"location\": location,\n",
    "                        \"min_max_avg_int\": min_max_avg_int,\n",
    "                        \"total_nuclei\": total_nuclei,\n",
    "                        \"marker+_nuclei\": marker_pos_nuclei,\n",
    "                        \"%_marker+_cells\": perc_marker_pos_cells,\n",
    "                        \"slicing_factor_xy\": slicing_factor_xy,\n",
    "                        \"slicing_factor_z\": slicing_factor_z\n",
    "                        }\n",
    "            \n",
    "            # Append the current data point to the stats_list\n",
    "            stats.append(stats_dict)  \n",
    "\n",
    "    # Create the necessary folder structure if it does not exist\n",
    "    try:\n",
    "        os.makedirs(str(results_folder))\n",
    "        print(f\"Output folder created: {results_folder}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Output folder already exists: {results_folder}\")\n",
    "\n",
    "    # Transform into a dataframe to store it as .csv later\n",
    "    df = pd.DataFrame(stats)\n",
    "\n",
    "    # Define the .csv path\n",
    "    csv_path = results_folder / f\"BP_marker_+_label_avg_int.csv\"\n",
    "\n",
    "    # Append to the .csv with new data points each round\n",
    "    df.to_csv(csv_path, mode=\"a\", index=False, header=not os.path.isfile(csv_path))\n",
    "\n",
    "# Show the updated .csv \n",
    "csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "csv_df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
