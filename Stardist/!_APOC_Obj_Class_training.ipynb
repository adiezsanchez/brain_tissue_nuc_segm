{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Single image - APOC Object Classifier training</h2>\n",
    "\n",
    "The following notebook is able to process multichannel 3D stack or 2D image (<code>.czi</code>, <code>.nd2</code> files) and allows you to:\n",
    "\n",
    "1. Inspect your images in Napari.\n",
    "2. Train an Object Classifier based on signal intensity in 2D or 3D images\n",
    "3. Visualize the results after the training.\n",
    "4. Correct your annotations and retrain.\n",
    "5. Save the resulting classifier to use it in SP and BP_Object_Classifier.ipynb\n",
    "\n",
    "Remember that to train your classifier you **must generate <code>full_image</code> nuclei labels first**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import apoc\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import napari\n",
    "import os\n",
    "import sys\n",
    "from utils_stardist import get_gpu_details, list_images, read_image, maximum_intensity_projection, simulate_cytoplasm_chunked_3d, simulate_cell_chunked_3d, simulate_cytoplasm, simulate_cell\n",
    "\n",
    "get_gpu_details()\n",
    "\n",
    "\n",
    "cle.select_device('RTX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the directory where your images are stored (.nd2 or .czi files)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "# At this point you should have generate the nuclei label predictions in advance\n",
    "directory_path = Path(\"../raw_data/test_data\")\n",
    "\n",
    "# Define the channels for which you want to train the ObjectClassifier using the following structure:\n",
    "# markers = [(channel_name, channel_nr, cellular_location),(..., ..., ...)]\n",
    "# cellular locations can be \"nucleus\", \"cytoplasm\" or \"cell\" (cell being the sum volume of nucleus and cytoplasm)\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# i.e. markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "# If your images have a different file format (i.e. .tif), change the function below like this: list_images(directory_path, format=\".tif\")\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Open each image in the directory</h3>\n",
    "You can do so by changing the number within the brackets below <code>image = images[0]</code>. Match the <code>slicing factor</code> to the one you will use during your nuclei label prediction and analysis.\n",
    "\n",
    "Choose an image to train your classifier on (0 defines the first image in the directory)\n",
    "\n",
    "The image should contain all classes (i.e. negative, positive, high intensity, low intensity) that are present in your dataset.\n",
    "\n",
    "Under <code>marker_name</code> input the name of the marker that you wish to load and train the classifier on. You must train the classifier for all the markers you plan to analyze later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image on which you will train your classifier (0 defines the first image in the directory)\n",
    "# The image should contain all classes (i.e. negative, positive, high intensity, low intensity) that are present in your dataset\n",
    "image = images[0]\n",
    "\n",
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "# Try and use the same factors that you applied during your nuclei label prediction and analysis\n",
    "slicing_factor_xy = None # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 3\n",
    "\n",
    "# Segmentation type (\"2D\" or \"3D\"). \n",
    "# 2D takes a z-stack as input, performs MIP (Maximum Intensity Projection) and predicts nuclei from the resulting projection (faster, useful for single layers of cells)\n",
    "# 3D is more computationally expensive. Predicts 3D nuclear volumes, useful for multilayered structures\n",
    "segmentation_type = \"3D\"\n",
    "\n",
    "# Nuclear segmentation model type (\"Stardist\")\n",
    "# Choose your Stardist fine-tuned model (model_name) from stardist_models folder\n",
    "model_name = \"MEC0.1\"\n",
    "\n",
    "# Type the ROI name you wish to load (by default it is \"full_image\")\n",
    "# It is recommended to traom the ObjectClassifier based on the full imag\n",
    "roi_name = \"full_image\"\n",
    "\n",
    "# Choose the channel you want to use to train the ObjectClassifier for:\n",
    "marker_name = \"neun\"\n",
    "\n",
    "# Read image, apply slicing if needed and return filename and img as a np array\n",
    "img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "nuclei_preds_path =  directory_path / \"nuclei_preds\" / segmentation_type / model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cellular compartment labels to Napari to start annotating your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first and second values (channel and location) of the corresponding tuple in markers\n",
    "for item in markers:\n",
    "    if item[0] == marker_name:\n",
    "        marker_channel = item[1]\n",
    "        location = item[2]\n",
    "        break  # Stop searching once the marker is found\n",
    "\n",
    "# Close any previous Napari instances that are open, ignore WARNING messages\n",
    "try:\n",
    "    viewer.close()\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "if segmentation_type == \"3D\":\n",
    "\n",
    "    # Load Napari viewer\n",
    "    viewer = napari.Viewer(ndisplay=2)\n",
    "    # Slice marker stack\n",
    "    marker_img = img[marker_channel]\n",
    "    viewer.add_image(marker_img)\n",
    "\n",
    "elif segmentation_type == \"2D\":\n",
    "\n",
    "    # Generate maximum intensity projection \n",
    "    img = maximum_intensity_projection(img)\n",
    "    # Load Napari viewer\n",
    "    viewer = napari.Viewer(ndisplay=2)\n",
    "    # Slice marker stack\n",
    "    marker_img = img[marker_channel]\n",
    "    viewer.add_image(marker_img)\n",
    "\n",
    "# Load nuclei labels and transform them into cell or cytoplasm labels if necessary\n",
    "try:\n",
    "    # Read the nuclei predictions per ROI\n",
    "    labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "    print(f\"Pre-computed nuclei labels found for {filename}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    sys.exit(f\"Nuclei labels for filename: {filename} ROI: {roi_name} not found. Please generate them using 002_BP_Predict_nuclei_labels.ipynb\")\n",
    "\n",
    "if location == \"cytoplasm\":\n",
    "    if segmentation_type == \"3D\":\n",
    "        print(f\"Generating {segmentation_type} cytoplasm labels for: {marker_name}\")\n",
    "        # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "        labels = simulate_cytoplasm_chunked_3d(labels, dilation_radius=2, erosion_radius=0, chunk_size=(labels.shape[0], 1024, 1024))\n",
    "\n",
    "    elif segmentation_type == \"2D\":\n",
    "        print(f\"Generating {segmentation_type} cytoplasm labels for: {marker_name}\")\n",
    "        # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "        labels = simulate_cytoplasm(labels, dilation_radius=2, erosion_radius=0)\n",
    "\n",
    "elif location == \"cell\":\n",
    "    if segmentation_type == \"3D\":\n",
    "        print(f\"Generating {segmentation_type} cell labels for: {marker_name}\")\n",
    "        # Simulate a cell volume by dilating the nuclei \n",
    "        labels = simulate_cell_chunked_3d(labels, dilation_radius=2, erosion_radius=0, chunk_size=(labels.shape[0], 1024, 1024))\n",
    "\n",
    "    elif segmentation_type == \"2D\":\n",
    "        print(f\"Generating {segmentation_type} cell labels for: {marker_name}\")\n",
    "        # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "        labels = simulate_cell(labels, dilation_radius=2, erosion_radius=0)\n",
    "\n",
    "viewer.add_labels(labels, opacity=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Annotation in Napari</h2>\n",
    "\n",
    "In this example we have cells negative for Neun (label 1), low Neun (label 2) and high Neun cells (label 3). Follow the next steps to annotate your data in Napari:\n",
    "\n",
    "1. Navigate through your stack and choose a good representative slice, alternatively switch to 3D mode and annotate in 3D.\n",
    "2. Create a new labels layer.\n",
    "3. Start annotating your different classes starting with negative cells (label 1). In this case we have low Neun (label 2) and high Neun cells (label 3). You can use points for specificity or paint lines across the objects. Empty space is not accounted for, only the object that your annotation touches.\n",
    "4. Once you are done annotating, keep Napari open and run the next cells.\n",
    "\n",
    "<video controls>\n",
    "  <source src=\"../assets/apoc_oc_annotation.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\n",
    "If you have already trained your classifier skip the next couple of cells and run the last one to see how the classifier applies to other images in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder structure to store resulting Object Classifiers\n",
    "apoc_path = Path(\"APOC_ObjectClassifiers\") / directory_path.name\n",
    "try:\n",
    "    os.makedirs(apoc_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Define features on which the classifier will be trained on (see train -help for full list of features)\n",
    "features = 'min_intensity,max_intensity,sum_intensity,mean_intensity,standard_deviation_intensity'\n",
    "\n",
    "cl_filename = f\"./{apoc_path}/ObjClass_{segmentation_type}_ch{marker_channel}.cl\"\n",
    "\n",
    "# Create an object classifier\n",
    "apoc.erase_classifier(cl_filename) # Delete it if it was existing before\n",
    "classifier = apoc.ObjectClassifier(cl_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not happy with the classifier go back to Napari and edit the \"Labels\" layer with a few more annotations, then run the cells below to fetch your modifications, train the classifier again and display the updated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect user input from Napari and train/retrain the ObjectClasifier based on it\n",
    "user_input = user_input = viewer.layers[\"Labels\"].data\n",
    "\n",
    "# Train or retrain your classifier\n",
    "classifier.train(features, labels, user_input, marker_img, continue_training=True)\n",
    "\n",
    "# Print the weights of each feature in the decision process\n",
    "classifier.feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell below loads the pre-trained classifier from disk and applies it to the corresponding intensity channel and labels displayed in Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoc_path = Path(\"APOC_ObjectClassifiers\") / directory_path.name\n",
    "cl_filename = f\"./{apoc_path}/ObjClass_{segmentation_type}_ch{marker_channel}.cl\"\n",
    "\n",
    "# Reload the classifier from disc to use the latest version\n",
    "classifier = apoc.ObjectClassifier(cl_filename)\n",
    "\n",
    "# Determine object classification\n",
    "result = classifier.predict(labels, marker_img)\n",
    "\n",
    "# Show the result\n",
    "viewer.add_labels(result, name='classification')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
